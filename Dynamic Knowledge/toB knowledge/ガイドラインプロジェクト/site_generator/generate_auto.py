#!/usr/bin/env python3
"""
è‡ªå‹•æ¤œå‡ºå‹ã‚µã‚¤ãƒˆç”Ÿæˆãƒ„ãƒ¼ãƒ«
Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã™ã‚‹ã ã‘ã§è‡ªå‹•çš„ã«ã‚µã‚¤ãƒˆã«åæ˜ ã•ã‚Œã‚‹
"""

import os
import shutil
import markdown
from pathlib import Path
import re
import json
import yaml
from datetime import datetime
from bs4 import BeautifulSoup

class AutoSiteGenerator:
    def __init__(self, content_dir="../01_ç¾è¡Œã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³/ã‚µã‚¤ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„", 
                 output_dir="../site_output",
                 template_dir="_templates"):
        self.content_dir = Path(content_dir)
        self.output_dir = Path(output_dir)
        self.template_dir = Path(template_dir)
        self.pages = []
        
    def extract_frontmatter(self, content):
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æŠ½å‡º"""
        if content.startswith('---\n'):
            try:
                parts = content.split('---\n', 2)
                if len(parts) >= 3:
                    frontmatter = yaml.safe_load(parts[1])
                    markdown_content = parts[2]
                    return frontmatter, markdown_content
            except:
                pass
        return {}, content
    
    def scan_markdown_files(self):
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦ãƒšãƒ¼ã‚¸æƒ…å ±ã‚’åé›†"""
        self.pages = []
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã¯é™¤å¤–
        exclude_dirs = ['ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–', 'archive', 'Archive', '_archive']
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’èµ°æŸ»
        for md_file in self.content_dir.rglob('*.md'):
            # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—
            if any(exclude_dir in md_file.parts for exclude_dir in exclude_dirs):
                continue
            # ç›¸å¯¾ãƒ‘ã‚¹ã‚’å–å¾—
            relative_path = md_file.relative_to(self.content_dir)
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›
            if "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†" in md_file.name:
                print(f"DEBUG: {md_file.name}")
                print(f"  - Full path: {md_file}")
                print(f"  - Relative path: {relative_path}")
                print(f"  - Parts: {relative_path.parts}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æŠ½å‡º
            frontmatter, markdown_content = self.extract_frontmatter(content)
            
            # ãƒšãƒ¼ã‚¸æƒ…å ±ã‚’æ§‹ç¯‰
            page_info = {
                'source': str(md_file),
                'content': markdown_content,
                'filename': md_file.name,
                'relative_path': str(relative_path),
            }
            
            # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‹ã‚‰æƒ…å ±ã‚’å–å¾—ï¼ˆãªã‘ã‚Œã°è‡ªå‹•ç”Ÿæˆï¼‰
            if frontmatter:
                page_info['title'] = frontmatter.get('title', self.clean_filename(md_file.stem))
                page_info['category'] = frontmatter.get('category', self.guess_category(relative_path))
                page_info['order'] = frontmatter.get('order', self.extract_order(md_file.name))
                page_info['date'] = frontmatter.get('date', None)
                page_info['tags'] = frontmatter.get('tags', [])
            else:
                # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãŒãªã„å ´åˆã¯è‡ªå‹•æ¨æ¸¬
                page_info['title'] = self.clean_filename(md_file.stem)
                page_info['category'] = self.guess_category(relative_path)
                page_info['order'] = self.extract_order(md_file.name)
                page_info['date'] = None
                page_info['tags'] = []
            
            # ãƒ‡ãƒãƒƒã‚°ï¼šãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã®ã‚³ãƒ„ã®ã‚«ãƒ†ã‚´ãƒªã‚’ç¢ºèª
            if "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†" in md_file.name:
                print(f"  - Assigned category: {page_info['category']}")
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            page_info['output_name'] = self.safe_filename(md_file.stem, md_file.name) + '.html'
            
            self.pages.append(page_info)
        
        # é‡è¤‡ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è§£æ±º
        self._resolve_duplicate_filenames()
        
        # ã‚½ãƒ¼ãƒˆï¼ˆã‚«ãƒ†ã‚´ãƒª â†’ order â†’ ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
        self.pages.sort(key=lambda x: (
            x['category'],
            x['order'],
            x['filename']
        ))
    
    def guess_category(self, relative_path):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’æ¨æ¸¬"""
        parts = relative_path.parts
        if len(parts) > 1:
            # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’ã‚«ãƒ†ã‚´ãƒªã¨ã—ã¦ä½¿ç”¨
            category = parts[0]
            # ã‚«ãƒ†ã‚´ãƒªåã®æ­£è¦åŒ–ï¼ˆç•ªå·ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»ï¼‰
            category = re.sub(r'^\d+[_-]', '', category)
            
            if category == "åŸºæœ¬æƒ…å ±":
                return "åŸºæœ¬æƒ…å ±"
            elif category == "å•†è«‡ãƒãƒ‹ãƒ¥ã‚¢ãƒ«":
                return "å•†è«‡ãƒãƒ‹ãƒ¥ã‚¢ãƒ«"
            elif category == "ãã®ä»–":
                return "ãã®ä»–"
            elif category == "loomã®å‹•ç”»":
                return "Loomå‹•ç”»"
            else:
                return category
        # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ŒåŸºæœ¬æƒ…å ±ã€ã«åˆ†é¡
        return "åŸºæœ¬æƒ…å ±"
    
    def extract_order(self, filename):
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰é †åºã‚’æŠ½å‡ºï¼ˆä¾‹: 01_xxx.md â†’ 1ï¼‰"""
        match = re.match(r'^(\d+)', filename)
        if match:
            return int(match.group(1))
        return 999
    
    def clean_filename(self, name):
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚¿ã‚¤ãƒˆãƒ«ç”¨ã«æ•´å½¢"""
        # æ•°å­—ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤
        name = re.sub(r'^\d+[_-]', '', name)
        # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚„ãƒã‚¤ãƒ•ãƒ³ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«
        name = re.sub(r'[_-]', ' ', name)
        # å˜èªã®å…ˆé ­ã‚’å¤§æ–‡å­—ã«
        return name.title()
    
    def safe_filename(self, name, original_filename=''):
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å®‰å…¨ãªHTMLåã«å¤‰æ›ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰"""
        # æ•°å­—ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤
        name = re.sub(r'^\d+[_-]', '', name)
        
        # æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åã®å¤‰æ›ãƒ†ãƒ¼ãƒ–ãƒ«
        replacements = {
            'ã¯ã˜ã‚ã«': 'index',
            'ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã®å¿ƒå¾—': 'director_mindset',
            'å…¨ä½“ã®æ¥­å‹™ãƒ—ãƒ­ã‚»ã‚¹': 'business_process',
            'ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¬ã‚¤ãƒ‰': 'communication_guide',
            'ä»£è¡¨çš„ãªãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°': 'troubleshooting',
            'ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è¦ç‚¹ã¾ã¨ã‚': 'guideline_summary',
            'å®Ÿè·µæ”¹å–„äº‹ä¾‹é›†': 'improvement_cases',
            'æ–°æ©Ÿèƒ½ã®ä½¿ã„æ–¹': 'new_features',
            'æ–°è¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¿½åŠ æ–¹æ³•': 'new_features',
            'ã‚ˆãã‚ã‚‹è³ªå•FAQ': 'faq',
            'ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆFAQï¼‰': 'faq',
            'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã®ã‚³ãƒ„': 'project_management_tips',
            'loomãƒªãƒ³ã‚¯é›†': 'loom_links',
            'æ–‡å­—èµ·ã“ã—': 'transcript'
        }
        
        # å¤‰æ›ãƒ†ãƒ¼ãƒ–ãƒ«ã§ä¸€è‡´ã™ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°ä½¿ç”¨
        for jp, en in replacements.items():
            if jp in name:
                return en
        
        # ä¸€è‡´ã—ãªã„å ´åˆã¯å®‰å…¨ãªå½¢å¼ã«å¤‰æ›
        # æ—¥æœ¬èªãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ç°¡å˜ãªå¤‰æ›ã‚’è©¦ã¿ã‚‹
        if re.search(r'[\u3040-\u309f\u30a0-\u30ff\u4e00-\u9faf]', name):
            # ãƒ•ã‚¡ã‚¤ãƒ«åã«ç•ªå·ãŒã‚ã‚Œã°åˆ©ç”¨
            match = re.match(r'^(\d+)', original_filename)
            if match:
                return f'page_{match.group(1)}'
            else:
                # ç•ªå·ãŒãªã‘ã‚Œã°é€£ç•ªã‚’ä»˜ä¸
                return f'page_{len(self.pages) + 1}'
        
        # è‹±æ•°å­—ã®ã¿ã®å ´åˆ
        safe_name = re.sub(r'[^\w\s-]', '', name)
        safe_name = re.sub(r'\s+', '_', safe_name).lower()
        
        return safe_name if safe_name else 'untitled'
    
    def _resolve_duplicate_filenames(self):
        """é‡è¤‡ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è§£æ±º"""
        filename_counts = {}
        
        # é‡è¤‡ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        for page in self.pages:
            output_name = page['output_name']
            if output_name in filename_counts:
                filename_counts[output_name] += 1
            else:
                filename_counts[output_name] = 1
        
        # é‡è¤‡ãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã«ç•ªå·ã‚’ä»˜ä¸
        filename_counters = {}
        for page in self.pages:
            output_name = page['output_name']
            if filename_counts[output_name] > 1:
                if output_name not in filename_counters:
                    filename_counters[output_name] = 1
                else:
                    filename_counters[output_name] += 1
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã«ç•ªå·ã‚’è¿½åŠ 
                base_name = output_name.replace('.html', '')
                page['output_name'] = f"{base_name}_{filename_counters[output_name]}.html"
    
    def generate_sidebar(self):
        """ãƒšãƒ¼ã‚¸æƒ…å ±ã‹ã‚‰ã‚µã‚¤ãƒ‰ãƒãƒ¼HTMLã‚’ç”Ÿæˆ"""
        categories = {}
        
        # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«ãƒšãƒ¼ã‚¸ã‚’åˆ†é¡
        for page in self.pages:
            category = page['category']
            if category not in categories:
                categories[category] = []
            categories[category].append(page)
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼HTMLç”Ÿæˆ
        sidebar_html = '''<div class="sidebar-header">
<a href="index.html" style="text-decoration: none; color: inherit;">
<h1>Harukazeã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h1>
</a>
<p>æ³•äººäº‹æ¥­ å“è³ªç®¡ç†ãƒãƒ‹ãƒ¥ã‚¢ãƒ«</p>
</div>
<nav class="sidebar-nav">'''
        
        # ã‚«ãƒ†ã‚´ãƒªã®è¡¨ç¤ºé †åºã‚’å®šç¾©
        category_order = ["åŸºæœ¬æƒ…å ±", "å•†è«‡ãƒãƒ‹ãƒ¥ã‚¢ãƒ«", "ãã®ä»–", "Loomå‹•ç”»"]
        
        # å®šç¾©ã•ã‚ŒãŸé †åºã§ã‚«ãƒ†ã‚´ãƒªã‚’è¡¨ç¤º
        for category in category_order:
            if category in categories:
                pages = categories[category]
                sidebar_html += f'''
<div class="category">
<div class="category-title">{category}</div>'''
                
                for page in pages:
                    sidebar_html += f'''
<a href="{page['output_name']}" class="nav-item">{page['title']}</a>'''
                
                sidebar_html += '\n</div>'
        
        # å®šç¾©ã•ã‚Œã¦ã„ãªã„ã‚«ãƒ†ã‚´ãƒªã‚‚è¿½åŠ 
        for category, pages in categories.items():
            if category not in category_order:
                sidebar_html += f'''
<div class="category">
<div class="category-title">{category}</div>'''
                
                for page in pages:
                    sidebar_html += f'''
<a href="{page['output_name']}" class="nav-item">{page['title']}</a>'''
                
                sidebar_html += '\n</div>'
        
        sidebar_html += '\n</nav>'
        return sidebar_html
    
    def generate_search_index(self):
        """æ¤œç´¢ç”¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆ"""
        search_index = []
        
        for page in self.pages:
            # Markdownã‚’ãƒ‘ãƒ¼ã‚¹
            md = markdown.Markdown(extensions=['extra', 'codehilite', 'toc', 'nl2br'])
            html_content = md.convert(page['content'])
            
            # HTMLã‚¿ã‚°ã‚’é™¤å»ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã®ã¿æŠ½å‡º
            soup = BeautifulSoup(html_content, 'html.parser')
            text_content = soup.get_text()
            
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«åˆ†å‰²ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
            sections = []
            lines = text_content.split('\n')
            current_section = {
                'title': page['title'],
                'content': '',
                'level': 0
            }
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¦‹å‡ºã—ã”ã¨ã«åˆ†å‰²
            for line in page['content'].split('\n'):
                line = line.strip()
                
                # è¦‹å‡ºã—ã‚’æ¤œå‡º
                heading_match = re.match(r'^(#{1,3})\s+(.+)$', line)
                if heading_match:
                    # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                    if current_section['content']:
                        sections.append(current_section.copy())
                    
                    level = len(heading_match.group(1))
                    title = heading_match.group(2)
                    
                    # æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
                    current_section = {
                        'title': title,
                        'content': '',
                        'level': level
                    }
                else:
                    # è¦‹å‡ºã—ä»¥å¤–ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½åŠ 
                    if line:
                        current_section['content'] += line + ' '
            
            # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
            if current_section['content']:
                sections.append(current_section)
            
            # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ 
            for section in sections:
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆï¼ˆã‚¢ãƒ³ã‚«ãƒ¼ãƒªãƒ³ã‚¯ç”¨ï¼‰
                section_id = re.sub(r'[^\w\s-]', '', section['title'])
                section_id = re.sub(r'\s+', '-', section_id).lower()
                
                search_index.append({
                    'pageTitle': page['title'],
                    'sectionTitle': section['title'],
                    'content': section['content'][:300],  # æœ€åˆã®300æ–‡å­—
                    'url': page['output_name'],
                    'sectionId': section_id,
                    'category': page['category']
                })
        
        return search_index
    
    def generate_site(self):
        """ã‚µã‚¤ãƒˆå…¨ä½“ã‚’ç”Ÿæˆ"""
        print("ğŸ” Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
        self.scan_markdown_files()
        print(f"ğŸ“„ {len(self.pages)}å€‹ã®ãƒšãƒ¼ã‚¸ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æº–å‚™
        if self.output_dir.exists():
            shutil.rmtree(self.output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿
        template_path = self.template_dir / "page_light.html"
        with open(template_path, 'r', encoding='utf-8') as f:
            template = f.read()
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’ç”Ÿæˆ
        sidebar_html = self.generate_sidebar()
        
        # å„ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        md = markdown.Markdown(extensions=['extra', 'codehilite', 'toc', 'nl2br'])
        
        for i, page in enumerate(self.pages):
            print(f"âš¡ {page['title']} ã‚’ç”Ÿæˆä¸­...")
            
            # Markdownã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
            html_content = md.convert(page['content'])
            md.reset()
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸ‹ã‚è¾¼ã¿
            output = template.replace('{{TITLE}}', page['title'])
            output = output.replace('{{SIDEBAR}}', sidebar_html)
            output = output.replace('{{CONTENT}}', html_content)
            output = output.replace('{{PAGE_TITLE}}', page['title'])
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            output_path = self.output_dir / page['output_name']
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(output)
            
            # æœ€åˆã®ãƒšãƒ¼ã‚¸ã‚’index.htmlã¨ã—ã¦ã‚‚ã‚³ãƒ”ãƒ¼
            if i == 0:
                shutil.copy(output_path, self.output_dir / 'index.html')
        
        # æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆ
        search_index = self.generate_search_index()
        search_index_path = self.output_dir / 'search-index.json'
        with open(search_index_path, 'w', encoding='utf-8') as f:
            json.dump(search_index, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ã‚µã‚¤ãƒˆç”Ÿæˆå®Œäº†ï¼ {self.output_dir} ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        # ãƒšãƒ¼ã‚¸ä¸€è¦§ã‚’è¡¨ç¤º
        print("\nğŸ“š ç”Ÿæˆã•ã‚ŒãŸãƒšãƒ¼ã‚¸:")
        for category, pages in self.get_pages_by_category().items():
            print(f"\nã€{category}ã€‘")
            for page in pages:
                print(f"  - {page['title']} ({page['output_name']})")
    
    def get_pages_by_category(self):
        """ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«ãƒšãƒ¼ã‚¸ã‚’æ•´ç†"""
        categories = {}
        for page in self.pages:
            category = page['category']
            if category not in categories:
                categories[category] = []
            categories[category].append(page)
        return categories

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    generator = AutoSiteGenerator()
    generator.generate_site()

if __name__ == "__main__":
    main()